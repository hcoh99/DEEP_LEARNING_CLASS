{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36d8418c-cd55-4570-a940-09f0c00b819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756af27f-57cb-4122-bb6c-41b65c54434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./DSA_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77749140-0558-407a-8ac9-63f1affd86bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c1d1740-68fe-4df7-a596-3c21d6624533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83bd0e09-0f33-4c5f-9abd-c1cfb9a2eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbadb073-e180-4584-8751-856a421e6458",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['activity' , 'people'] ,  axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89da3c50-4f37-440e-8276-3bf6bccfaeca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29968</td>\n",
       "      <td>6.267229e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29974</td>\n",
       "      <td>7.403458e-07</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30068</td>\n",
       "      <td>5.802523e-07</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30088</td>\n",
       "      <td>5.398837e-07</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30041</td>\n",
       "      <td>6.787533e-07</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.19482</td>\n",
       "      <td>4.033226e-02</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.21407</td>\n",
       "      <td>2.212497e-02</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47131</td>\n",
       "      <td>9.656444e-02</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.17806</td>\n",
       "      <td>2.448990e-02</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.27751</td>\n",
       "      <td>5.251176e-02</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_min   LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  \\\n",
       "0         0.29968  6.267229e-07     0.000792      0.177075     -0.057119   \n",
       "1         0.29974  7.403458e-07     0.000860     -0.286918     -0.057268   \n",
       "2         0.30068  5.802523e-07     0.000762     -0.134430     -0.057068   \n",
       "3         0.30088  5.398837e-07     0.000735      0.021485     -0.056422   \n",
       "4         0.30041  6.787533e-07     0.000824     -0.148229     -0.055801   \n",
       "...           ...           ...          ...           ...           ...   \n",
       "9115      0.19482  4.033226e-02     0.200829     -0.040701      0.297666   \n",
       "9116      0.21407  2.212497e-02     0.148745     -0.266377      0.224716   \n",
       "9117     -0.47131  9.656444e-02     0.310748     -0.009505     -0.237786   \n",
       "9118     -0.17806  2.448990e-02     0.156493      0.050624      0.533023   \n",
       "9119     -0.27751  5.251176e-02     0.229154     -0.342228      0.491919   \n",
       "\n",
       "      LL_zmag_max  LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "0       -0.054963    -0.059241  6.778722e-07     0.000823      0.036729  \n",
       "1       -0.054945    -0.059589  7.032302e-07     0.000839      0.347471  \n",
       "2       -0.054711    -0.059065  6.268222e-07     0.000792      0.045579  \n",
       "3       -0.053670    -0.058310  8.011245e-07     0.000895      0.240690  \n",
       "4       -0.053313    -0.057815  6.853423e-07     0.000828      0.258429  \n",
       "...           ...          ...           ...          ...           ...  \n",
       "9115     0.708480    -0.117430  4.135451e-02     0.203358     -0.310022  \n",
       "9116     0.554670    -0.250950  3.355704e-02     0.183186     -0.736410  \n",
       "9117     0.088854    -0.477260  2.026107e-02     0.142341      0.668438  \n",
       "9118     0.677800     0.055941  1.356379e-02     0.116464     -1.482489  \n",
       "9119     0.707920     0.251280  9.358254e-03     0.096738     -0.223302  \n",
       "\n",
       "[9120 rows x 270 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4a3aab6-6da8-4bb1-80ea-cf27c4809627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# LabelEncoder를 사용하여 문자열 레이블을 정수형 레이블로 변환\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# y_train과 y_test를 원-핫 인코딩으로 변환\n",
    "y_train = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test = to_categorical(y_test, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a4a83-91ef-4fdf-98ef-0dc6ae0d2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# split_sequence 함수 (수정됨)\n",
    "def split_sequence(sequence, labels, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        \n",
    "        # sequence에서 n_steps 크기만큼 데이터 추출\n",
    "        seq_x = sequence[i:end_ix]\n",
    "        \n",
    "        # labels에서 n_steps 크기만큼 레이블 추출\n",
    "        seq_y = labels[i:end_ix]\n",
    "        \n",
    "        # seq_y에서 가장 많이 등장한 레이블 선택\n",
    "        most_common_label = Counter(seq_y).most_common(1)[0][0]\n",
    "        \n",
    "        # X와 y에 추가\n",
    "        X.append(seq_x)\n",
    "        y.append(most_common_label)\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61422b37-9568-4361-9e92-98c1e612bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 데이터 적용\n",
    "sequence = df.drop(['activity','people'], axis=1).values  # 수치형 데이터\n",
    "labels = df['activity'].values  # 범주형 레이블 'Rings_binned'\n",
    "\n",
    "# 시퀀스 분리\n",
    "n_steps = 7\n",
    "X, y = split_sequence(sequence, labels, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "764d1923-f7ce-4343-bf33-15dc02ec17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e8113e-013e-472e-aa97-a02a820bda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame을 numpy 배열로 변환\n",
    "x_train = x_train.values\n",
    "x_test = x_test.values\n",
    "\n",
    "# numpy 배열로 변환한 후 reshape 적용\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d28b1158-f6ef-4a0e-995b-875f49bd3f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e306500-52ad-4fa1-99ad-7d8f586d9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d66ba-94a9-410d-bd1d-f04d0f0860f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bf7ce67-8cad-495e-bbe5-ffb58fc28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcb811-c8a7-4e73-9d01-1882ccdc4249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "981e7a22-1767-4719-9ea3-0aa1b640093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7024f27f-0a4d-4634-b6b9-96be3c26a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 270, 1)]     0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (Multi  (None, 270, 1)      7169        ['input_5[0][0]',                \n",
      " HeadAttention)                                                   'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 270, 1)       0           ['multi_head_attention_12[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_24 (LayerN  (None, 270, 1)      2           ['dropout_27[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (TFOpL  (None, 270, 1)      0           ['layer_normalization_24[0][0]', \n",
      " ambda)                                                           'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 270, 4)       8           ['tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " dropout_28 (Dropout)           (None, 270, 4)       0           ['conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 270, 1)       5           ['dropout_28[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_25 (LayerN  (None, 270, 1)      2           ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (TFOpL  (None, 270, 1)      0           ['layer_normalization_25[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_24[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_13 (Multi  (None, 270, 1)      7169        ['tf.__operators__.add_25[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " dropout_29 (Dropout)           (None, 270, 1)       0           ['multi_head_attention_13[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_26 (LayerN  (None, 270, 1)      2           ['dropout_29[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (TFOpL  (None, 270, 1)      0           ['layer_normalization_26[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_25[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 270, 4)       8           ['tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 270, 4)       0           ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 270, 1)       5           ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_27 (LayerN  (None, 270, 1)      2           ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (TFOpL  (None, 270, 1)      0           ['layer_normalization_27[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_26[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_14 (Multi  (None, 270, 1)      7169        ['tf.__operators__.add_27[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 270, 1)       0           ['multi_head_attention_14[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_28 (LayerN  (None, 270, 1)      2           ['dropout_31[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (TFOpL  (None, 270, 1)      0           ['layer_normalization_28[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_27[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 270, 4)       8           ['tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 270, 4)       0           ['conv1d_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 270, 1)       5           ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_29 (LayerN  (None, 270, 1)      2           ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (TFOpL  (None, 270, 1)      0           ['layer_normalization_29[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_28[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention_15 (Multi  (None, 270, 1)      7169        ['tf.__operators__.add_29[0][0]',\n",
      " HeadAttention)                                                   'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 270, 1)       0           ['multi_head_attention_15[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization_30 (LayerN  (None, 270, 1)      2           ['dropout_33[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (TFOpL  (None, 270, 1)      0           ['layer_normalization_30[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_29[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 270, 4)       8           ['tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " dropout_34 (Dropout)           (None, 270, 4)       0           ['conv1d_30[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 270, 1)       5           ['dropout_34[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization_31 (LayerN  (None, 270, 1)      2           ['conv1d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (TFOpL  (None, 270, 1)      0           ['layer_normalization_31[0][0]', \n",
      " ambda)                                                           'tf.__operators__.add_30[0][0]']\n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 1)           0           ['tf.__operators__.add_31[0][0]']\n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          256         ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 128)          0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 19)           2451        ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,451\n",
      "Trainable params: 31,451\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 11:04:06.428524: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - ETA: 0s - loss: 2.9306 - accuracy: 0.0687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 11:07:20.828038: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 218s 2s/step - loss: 2.9306 - accuracy: 0.0687 - val_loss: 2.8836 - val_accuracy: 0.0890\n",
      "Epoch 2/150\n",
      "92/92 [==============================] - 206s 2s/step - loss: 2.8757 - accuracy: 0.1020 - val_loss: 2.8376 - val_accuracy: 0.1151\n",
      "Epoch 3/150\n",
      "92/92 [==============================] - 206s 2s/step - loss: 2.8252 - accuracy: 0.1062 - val_loss: 2.7945 - val_accuracy: 0.1137\n",
      "Epoch 4/150\n",
      "92/92 [==============================] - 205s 2s/step - loss: 2.7805 - accuracy: 0.1103 - val_loss: 2.7540 - val_accuracy: 0.1089\n",
      "Epoch 5/150\n",
      "92/92 [==============================] - 206s 2s/step - loss: 2.7374 - accuracy: 0.1059 - val_loss: 2.7132 - val_accuracy: 0.1110\n",
      "Epoch 6/150\n",
      "92/92 [==============================] - 205s 2s/step - loss: 2.6909 - accuracy: 0.1114 - val_loss: 2.6765 - val_accuracy: 0.1110\n",
      "Epoch 7/150\n",
      "92/92 [==============================] - 204s 2s/step - loss: 2.6510 - accuracy: 0.1114 - val_loss: 2.6440 - val_accuracy: 0.1110\n",
      "Epoch 8/150\n",
      "77/92 [========================>.....] - ETA: 32s - loss: 2.6282 - accuracy: 0.1057"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     21\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf29_py39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e33a65b1-2136-4e45-b08a-37663515a1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9120, 272)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "745bbe66-d6a6-4ff0-9a01-f2d3450a18ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "666ee341-55e9-4398-a3e5-5acb0c951b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe029d0f-a334-4978-8ea6-0e9f9fe18991",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"Normal\", \"Abnormal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d03b977a-be6c-4b21-b326-4d41652caeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sitting', 'standing', 'lyingBack', 'lyingRigh', 'ascendingStairs',\n",
       "       'decendingStairs', 'standingInElevatorStill', 'movingInElevator',\n",
       "       'walkingLot', 'walkingTreadmillFlat', 'walkingTreadmillIncline',\n",
       "       'runningTreadmill', 'stepper', 'crossTrainer', 'cyclingHorizontal',\n",
       "       'cyclingVertical', 'rowing', 'jumping', 'basketBall'], dtype=object)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a35e116-2293-471c-befb-7df45dfac55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9x/8whwzmnj6z5bjc7_h1txd9_r0000gn/T/ipykernel_98369/3353177650.py:11: FutureWarning: pandas.value_counts is deprecated and will be removed in a future version. Use pd.Series(obj).value_counts() instead.\n",
      "  count_classes = pd.value_counts(df['Class'], sort=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 'lyingBack'과 'lyingRigh'는 Normal(0)로, 'jumping'은 Abnormal(1)로 설정\n",
    "df['Class'] = df['activity'].apply(lambda x: 0 if x in ['lyingBack', 'lyingRigh'] else (1 if x == 'jumping' else None))\n",
    "\n",
    "# 결측값 제거 (필요에 따라 적용)\n",
    "df = df.dropna(subset=['Class'])\n",
    "\n",
    "# Class별 샘플 수 세기\n",
    "count_classes = pd.value_counts(df['Class'], sort=True)\n",
    "\n",
    "# 막대 그래프 그리기\n",
    "LABELS = ['Normal', 'Abnormal']\n",
    "count_classes.plot(kind='bar', rot=0)\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9f9ed644-71f7-46f1-bede-db916cb85861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0.0    960\n",
       "1.0    480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f69c8b23-2607-4e25-8a4a-5904c2be29e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 273)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abnormal = df[df.Class == 1]\n",
    "normal = df[df.Class == 0]\n",
    "Abnormal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "103da817-da5b-4948-9676-13b9caa8d5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 273)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d8b3f885-0a60-4dcc-884c-f6ebd572e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['T_xacc_mean', 'T_xacc_max', 'T_xacc_min', 'T_xacc_var', 'T_xacc_std',\n",
      "       'T_xacc_skew', 'T_yacc_mean', 'T_yacc_max', 'T_yacc_min', 'T_yacc_var',\n",
      "       ...\n",
      "       'LL_ymag_skew', 'LL_zmag_mean', 'LL_zmag_max', 'LL_zmag_min',\n",
      "       'LL_zmag_var', 'LL_zmag_std', 'LL_zmag_skew', 'activity', 'people',\n",
      "       'Class'],\n",
      "      dtype='object', length=273)\n",
      "Index(['T_xacc_mean', 'T_xacc_max', 'T_xacc_min', 'T_xacc_var', 'T_xacc_std',\n",
      "       'T_xacc_skew', 'T_yacc_mean', 'T_yacc_max', 'T_yacc_min', 'T_yacc_var',\n",
      "       ...\n",
      "       'LL_ymag_skew', 'LL_zmag_mean', 'LL_zmag_max', 'LL_zmag_min',\n",
      "       'LL_zmag_var', 'LL_zmag_std', 'LL_zmag_skew', 'activity', 'people',\n",
      "       'Class'],\n",
      "      dtype='object', length=273)\n"
     ]
    }
   ],
   "source": [
    "print(Abnormal.columns)\n",
    "print(normal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a0d3b0d6-1a2e-4cc1-afe6-b63023a561f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>8.978253</td>\n",
       "      <td>40.5460</td>\n",
       "      <td>-5.3871</td>\n",
       "      <td>133.210928</td>\n",
       "      <td>11.541704</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>-0.028485</td>\n",
       "      <td>4.6232</td>\n",
       "      <td>-7.3776</td>\n",
       "      <td>1.913818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>-0.452746</td>\n",
       "      <td>-0.42401</td>\n",
       "      <td>-0.48635</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>8.937468</td>\n",
       "      <td>40.4930</td>\n",
       "      <td>-6.7806</td>\n",
       "      <td>122.558637</td>\n",
       "      <td>11.070620</td>\n",
       "      <td>0.595402</td>\n",
       "      <td>-0.031455</td>\n",
       "      <td>2.9872</td>\n",
       "      <td>-5.4906</td>\n",
       "      <td>1.501715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587490</td>\n",
       "      <td>-0.433809</td>\n",
       "      <td>-0.40023</td>\n",
       "      <td>-0.46888</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.093940</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>9.275007</td>\n",
       "      <td>42.3080</td>\n",
       "      <td>-4.9602</td>\n",
       "      <td>145.592435</td>\n",
       "      <td>12.066169</td>\n",
       "      <td>0.793694</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>3.3550</td>\n",
       "      <td>-6.8576</td>\n",
       "      <td>1.742066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494886</td>\n",
       "      <td>-0.404305</td>\n",
       "      <td>-0.34281</td>\n",
       "      <td>-0.45115</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.243550</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>8.659709</td>\n",
       "      <td>42.1060</td>\n",
       "      <td>-7.8529</td>\n",
       "      <td>153.811145</td>\n",
       "      <td>12.402062</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>-0.141696</td>\n",
       "      <td>4.2339</td>\n",
       "      <td>-5.7269</td>\n",
       "      <td>1.638842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353853</td>\n",
       "      <td>-0.369328</td>\n",
       "      <td>-0.33381</td>\n",
       "      <td>-0.41835</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>-0.312305</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>9.504206</td>\n",
       "      <td>43.7370</td>\n",
       "      <td>-6.3691</td>\n",
       "      <td>158.982033</td>\n",
       "      <td>12.608808</td>\n",
       "      <td>0.760463</td>\n",
       "      <td>0.104321</td>\n",
       "      <td>4.0206</td>\n",
       "      <td>-7.3882</td>\n",
       "      <td>2.183937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>-0.400433</td>\n",
       "      <td>-0.35154</td>\n",
       "      <td>-0.43797</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.549612</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2.620502</td>\n",
       "      <td>2.6592</td>\n",
       "      <td>2.5891</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>-9.392025</td>\n",
       "      <td>-9.3424</td>\n",
       "      <td>-9.4207</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401254</td>\n",
       "      <td>-0.410987</td>\n",
       "      <td>-0.38221</td>\n",
       "      <td>-0.44605</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.597598</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2.613423</td>\n",
       "      <td>2.6572</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.368746</td>\n",
       "      <td>-9.398851</td>\n",
       "      <td>-9.3657</td>\n",
       "      <td>-9.4356</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>-0.411248</td>\n",
       "      <td>-0.36581</td>\n",
       "      <td>-0.43676</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>1.021454</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2.614750</td>\n",
       "      <td>2.6576</td>\n",
       "      <td>2.5654</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>-9.397350</td>\n",
       "      <td>-9.3628</td>\n",
       "      <td>-9.4313</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-0.409787</td>\n",
       "      <td>-0.37926</td>\n",
       "      <td>-0.43431</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.431012</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2.620167</td>\n",
       "      <td>2.6589</td>\n",
       "      <td>2.5781</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.114904</td>\n",
       "      <td>-9.397014</td>\n",
       "      <td>-9.3649</td>\n",
       "      <td>-9.4539</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409508</td>\n",
       "      <td>-0.409101</td>\n",
       "      <td>-0.36074</td>\n",
       "      <td>-0.44087</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>1.368666</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2.615565</td>\n",
       "      <td>2.6789</td>\n",
       "      <td>2.5734</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.608394</td>\n",
       "      <td>-9.398614</td>\n",
       "      <td>-9.3661</td>\n",
       "      <td>-9.4279</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413339</td>\n",
       "      <td>-0.410440</td>\n",
       "      <td>-0.38588</td>\n",
       "      <td>-0.43841</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "8160     8.978253     40.5460     -5.3871  133.210928   11.541704   \n",
       "8161     8.937468     40.4930     -6.7806  122.558637   11.070620   \n",
       "8162     9.275007     42.3080     -4.9602  145.592435   12.066169   \n",
       "8163     8.659709     42.1060     -7.8529  153.811145   12.402062   \n",
       "8164     9.504206     43.7370     -6.3691  158.982033   12.608808   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "1915     2.620502      2.6592      2.5891    0.000199    0.014113   \n",
       "1916     2.613423      2.6572      2.5815    0.000207    0.014387   \n",
       "1917     2.614750      2.6576      2.5654    0.000257    0.016018   \n",
       "1918     2.620167      2.6589      2.5781    0.000216    0.014691   \n",
       "1919     2.615565      2.6789      2.5734    0.000310    0.017610   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "8160     0.710995    -0.028485      4.6232     -7.3776    1.913818  ...   \n",
       "8161     0.595402    -0.031455      2.9872     -5.4906    1.501715  ...   \n",
       "8162     0.793694     0.043397      3.3550     -6.8576    1.742066  ...   \n",
       "8163     0.912284    -0.141696      4.2339     -5.7269    1.638842  ...   \n",
       "8164     0.760463     0.104321      4.0206     -7.3882    2.183937  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "1915     0.148452    -9.392025     -9.3424     -9.4207    0.000242  ...   \n",
       "1916     0.368746    -9.398851     -9.3657     -9.4356    0.000156  ...   \n",
       "1917    -0.007991    -9.397350     -9.3628     -9.4313    0.000214  ...   \n",
       "1918    -0.114904    -9.397014     -9.3649     -9.4539    0.000257  ...   \n",
       "1919     0.608394    -9.398614     -9.3661     -9.4279    0.000167  ...   \n",
       "\n",
       "      LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  LL_zmag_var  \\\n",
       "8160      0.026911     -0.452746     -0.42401     -0.48635     0.000261   \n",
       "8161      0.587490     -0.433809     -0.40023     -0.46888     0.000238   \n",
       "8162      0.494886     -0.404305     -0.34281     -0.45115     0.000443   \n",
       "8163      0.353853     -0.369328     -0.33381     -0.41835     0.000354   \n",
       "8164      0.329407     -0.400433     -0.35154     -0.43797     0.000246   \n",
       "...            ...           ...          ...          ...          ...   \n",
       "1915      0.401254     -0.410987     -0.38221     -0.44605     0.000099   \n",
       "1916      0.147180     -0.411248     -0.36581     -0.43676     0.000087   \n",
       "1917      0.032341     -0.409787     -0.37926     -0.43431     0.000073   \n",
       "1918      0.409508     -0.409101     -0.36074     -0.44087     0.000113   \n",
       "1919      0.413339     -0.410440     -0.38588     -0.43841     0.000072   \n",
       "\n",
       "      LL_zmag_std  LL_zmag_skew   activity  people  Class  \n",
       "8160     0.016168      0.032586    jumping      p1    1.0  \n",
       "8161     0.015440      0.093940    jumping      p1    1.0  \n",
       "8162     0.021043      0.243550    jumping      p1    1.0  \n",
       "8163     0.018816     -0.312305    jumping      p1    1.0  \n",
       "8164     0.015679      0.549612    jumping      p1    1.0  \n",
       "...           ...           ...        ...     ...    ...  \n",
       "1915     0.009967     -0.597598  lyingRigh      p8    0.0  \n",
       "1916     0.009306      1.021454  lyingRigh      p8    0.0  \n",
       "1917     0.008520      0.431012  lyingRigh      p8    0.0  \n",
       "1918     0.010620      1.368666  lyingRigh      p8    0.0  \n",
       "1919     0.008495      0.054973  lyingRigh      p8    0.0  \n",
       "\n",
       "[1440 rows x 273 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.concat([Abnormal, normal])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "92279a8b-e211-401b-9eb5-adfca8d63331",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = normal.drop(['Class', 'activity', 'people'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e3ae6c2-2abb-4f21-84af-c515e6d79137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-4.834646</td>\n",
       "      <td>-4.7185</td>\n",
       "      <td>-4.9049</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.632141</td>\n",
       "      <td>-0.501018</td>\n",
       "      <td>-0.41744</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56276</td>\n",
       "      <td>9.725263e-07</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.074676</td>\n",
       "      <td>-0.532664</td>\n",
       "      <td>-0.52993</td>\n",
       "      <td>-0.53521</td>\n",
       "      <td>9.585668e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-4.780810</td>\n",
       "      <td>-4.5850</td>\n",
       "      <td>-4.8833</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>1.052880</td>\n",
       "      <td>-0.480601</td>\n",
       "      <td>-0.40372</td>\n",
       "      <td>-0.63184</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56394</td>\n",
       "      <td>6.211659e-07</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.181526</td>\n",
       "      <td>-0.531169</td>\n",
       "      <td>-0.52940</td>\n",
       "      <td>-0.53365</td>\n",
       "      <td>7.608973e-07</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.372381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-4.804400</td>\n",
       "      <td>-4.7037</td>\n",
       "      <td>-4.8755</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>0.735226</td>\n",
       "      <td>-0.493925</td>\n",
       "      <td>-0.42616</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56445</td>\n",
       "      <td>4.579046e-07</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.263115</td>\n",
       "      <td>-0.530569</td>\n",
       "      <td>-0.52873</td>\n",
       "      <td>-0.53222</td>\n",
       "      <td>5.160537e-07</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.185587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-4.750563</td>\n",
       "      <td>-4.5696</td>\n",
       "      <td>-4.8977</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.066683</td>\n",
       "      <td>0.710263</td>\n",
       "      <td>-0.437358</td>\n",
       "      <td>-0.30877</td>\n",
       "      <td>-0.55225</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56420</td>\n",
       "      <td>4.703523e-07</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.060925</td>\n",
       "      <td>-0.531167</td>\n",
       "      <td>-0.52962</td>\n",
       "      <td>-0.53283</td>\n",
       "      <td>4.975523e-07</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.145321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-4.774916</td>\n",
       "      <td>-4.6741</td>\n",
       "      <td>-4.8457</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.324779</td>\n",
       "      <td>-0.459456</td>\n",
       "      <td>-0.38900</td>\n",
       "      <td>-0.53714</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56455</td>\n",
       "      <td>5.467316e-07</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.335811</td>\n",
       "      <td>-0.529804</td>\n",
       "      <td>-0.52706</td>\n",
       "      <td>-0.53251</td>\n",
       "      <td>1.292131e-06</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-0.026271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2.620502</td>\n",
       "      <td>2.6592</td>\n",
       "      <td>2.5891</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>-9.392025</td>\n",
       "      <td>-9.34240</td>\n",
       "      <td>-9.42070</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54522</td>\n",
       "      <td>9.195642e-05</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.401254</td>\n",
       "      <td>-0.410987</td>\n",
       "      <td>-0.38221</td>\n",
       "      <td>-0.44605</td>\n",
       "      <td>9.935077e-05</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.597598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2.613423</td>\n",
       "      <td>2.6572</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.368746</td>\n",
       "      <td>-9.398851</td>\n",
       "      <td>-9.36570</td>\n",
       "      <td>-9.43560</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.55652</td>\n",
       "      <td>7.375030e-05</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>-0.411248</td>\n",
       "      <td>-0.36581</td>\n",
       "      <td>-0.43676</td>\n",
       "      <td>8.659481e-05</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>1.021454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2.614750</td>\n",
       "      <td>2.6576</td>\n",
       "      <td>2.5654</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>-9.397350</td>\n",
       "      <td>-9.36280</td>\n",
       "      <td>-9.43130</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.53640</td>\n",
       "      <td>3.380089e-05</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-0.409787</td>\n",
       "      <td>-0.37926</td>\n",
       "      <td>-0.43431</td>\n",
       "      <td>7.258946e-05</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.431012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2.620167</td>\n",
       "      <td>2.6589</td>\n",
       "      <td>2.5781</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.114904</td>\n",
       "      <td>-9.397014</td>\n",
       "      <td>-9.36490</td>\n",
       "      <td>-9.45390</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54565</td>\n",
       "      <td>9.044032e-05</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.409508</td>\n",
       "      <td>-0.409101</td>\n",
       "      <td>-0.36074</td>\n",
       "      <td>-0.44087</td>\n",
       "      <td>1.127801e-04</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>1.368666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2.615565</td>\n",
       "      <td>2.6789</td>\n",
       "      <td>2.5734</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.608394</td>\n",
       "      <td>-9.398614</td>\n",
       "      <td>-9.36610</td>\n",
       "      <td>-9.42790</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54256</td>\n",
       "      <td>9.748789e-05</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.413339</td>\n",
       "      <td>-0.410440</td>\n",
       "      <td>-0.38588</td>\n",
       "      <td>-0.43841</td>\n",
       "      <td>7.216993e-05</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.054973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "960     -4.834646     -4.7185     -4.9049    0.001124    0.033529   \n",
       "961     -4.780810     -4.5850     -4.8833    0.003948    0.062835   \n",
       "962     -4.804400     -4.7037     -4.8755    0.001482    0.038496   \n",
       "963     -4.750563     -4.5696     -4.8977    0.004447    0.066683   \n",
       "964     -4.774916     -4.6741     -4.8457    0.001080    0.032868   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "1915     2.620502      2.6592      2.5891    0.000199    0.014113   \n",
       "1916     2.613423      2.6572      2.5815    0.000207    0.014387   \n",
       "1917     2.614750      2.6576      2.5654    0.000257    0.016018   \n",
       "1918     2.620167      2.6589      2.5781    0.000216    0.014691   \n",
       "1919     2.615565      2.6789      2.5734    0.000310    0.017610   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "960      0.632141    -0.501018    -0.41744    -0.59561    0.001016  ...   \n",
       "961      1.052880    -0.480601    -0.40372    -0.63184    0.001297  ...   \n",
       "962      0.735226    -0.493925    -0.42616    -0.59561    0.000863  ...   \n",
       "963      0.710263    -0.437358    -0.30877    -0.55225    0.003587  ...   \n",
       "964      0.324779    -0.459456    -0.38900    -0.53714    0.001059  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "1915     0.148452    -9.392025    -9.34240    -9.42070    0.000242  ...   \n",
       "1916     0.368746    -9.398851    -9.36570    -9.43560    0.000156  ...   \n",
       "1917    -0.007991    -9.397350    -9.36280    -9.43130    0.000214  ...   \n",
       "1918    -0.114904    -9.397014    -9.36490    -9.45390    0.000257  ...   \n",
       "1919     0.608394    -9.398614    -9.36610    -9.42790    0.000167  ...   \n",
       "\n",
       "      LL_ymag_min   LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  \\\n",
       "960       0.56276  9.725263e-07     0.000986      0.074676     -0.532664   \n",
       "961       0.56394  6.211659e-07     0.000788     -0.181526     -0.531169   \n",
       "962       0.56445  4.579046e-07     0.000677     -0.263115     -0.530569   \n",
       "963       0.56420  4.703523e-07     0.000686     -0.060925     -0.531167   \n",
       "964       0.56455  5.467316e-07     0.000739      0.335811     -0.529804   \n",
       "...           ...           ...          ...           ...           ...   \n",
       "1915     -0.54522  9.195642e-05     0.009589      0.401254     -0.410987   \n",
       "1916     -0.55652  7.375030e-05     0.008588      0.147180     -0.411248   \n",
       "1917     -0.53640  3.380089e-05     0.005814      0.032341     -0.409787   \n",
       "1918     -0.54565  9.044032e-05     0.009510      0.409508     -0.409101   \n",
       "1919     -0.54256  9.748789e-05     0.009874      0.413339     -0.410440   \n",
       "\n",
       "      LL_zmag_max  LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "960      -0.52993     -0.53521  9.585668e-07     0.000979     -0.193301  \n",
       "961      -0.52940     -0.53365  7.608973e-07     0.000872     -0.372381  \n",
       "962      -0.52873     -0.53222  5.160537e-07     0.000718      0.185587  \n",
       "963      -0.52962     -0.53283  4.975523e-07     0.000705     -0.145321  \n",
       "964      -0.52706     -0.53251  1.292131e-06     0.001137     -0.026271  \n",
       "...           ...          ...           ...          ...           ...  \n",
       "1915     -0.38221     -0.44605  9.935077e-05     0.009967     -0.597598  \n",
       "1916     -0.36581     -0.43676  8.659481e-05     0.009306      1.021454  \n",
       "1917     -0.37926     -0.43431  7.258946e-05     0.008520      0.431012  \n",
       "1918     -0.36074     -0.44087  1.127801e-04     0.010620      1.368666  \n",
       "1919     -0.38588     -0.43841  7.216993e-05     0.008495      0.054973  \n",
       "\n",
       "[960 rows x 270 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1f63fbc-59ec-4654-9691-084bd06d2cce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-4.834646</td>\n",
       "      <td>-4.7185</td>\n",
       "      <td>-4.9049</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.632141</td>\n",
       "      <td>-0.501018</td>\n",
       "      <td>-0.41744</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56276</td>\n",
       "      <td>9.725263e-07</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.074676</td>\n",
       "      <td>-0.532664</td>\n",
       "      <td>-0.52993</td>\n",
       "      <td>-0.53521</td>\n",
       "      <td>9.585668e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.193301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-4.780810</td>\n",
       "      <td>-4.5850</td>\n",
       "      <td>-4.8833</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>1.052880</td>\n",
       "      <td>-0.480601</td>\n",
       "      <td>-0.40372</td>\n",
       "      <td>-0.63184</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56394</td>\n",
       "      <td>6.211659e-07</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.181526</td>\n",
       "      <td>-0.531169</td>\n",
       "      <td>-0.52940</td>\n",
       "      <td>-0.53365</td>\n",
       "      <td>7.608973e-07</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.372381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-4.804400</td>\n",
       "      <td>-4.7037</td>\n",
       "      <td>-4.8755</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>0.735226</td>\n",
       "      <td>-0.493925</td>\n",
       "      <td>-0.42616</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56445</td>\n",
       "      <td>4.579046e-07</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.263115</td>\n",
       "      <td>-0.530569</td>\n",
       "      <td>-0.52873</td>\n",
       "      <td>-0.53222</td>\n",
       "      <td>5.160537e-07</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.185587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-4.750563</td>\n",
       "      <td>-4.5696</td>\n",
       "      <td>-4.8977</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.066683</td>\n",
       "      <td>0.710263</td>\n",
       "      <td>-0.437358</td>\n",
       "      <td>-0.30877</td>\n",
       "      <td>-0.55225</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56420</td>\n",
       "      <td>4.703523e-07</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.060925</td>\n",
       "      <td>-0.531167</td>\n",
       "      <td>-0.52962</td>\n",
       "      <td>-0.53283</td>\n",
       "      <td>4.975523e-07</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.145321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-4.774916</td>\n",
       "      <td>-4.6741</td>\n",
       "      <td>-4.8457</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.324779</td>\n",
       "      <td>-0.459456</td>\n",
       "      <td>-0.38900</td>\n",
       "      <td>-0.53714</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56455</td>\n",
       "      <td>5.467316e-07</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.335811</td>\n",
       "      <td>-0.529804</td>\n",
       "      <td>-0.52706</td>\n",
       "      <td>-0.53251</td>\n",
       "      <td>1.292131e-06</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-0.026271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2.620502</td>\n",
       "      <td>2.6592</td>\n",
       "      <td>2.5891</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>-9.392025</td>\n",
       "      <td>-9.34240</td>\n",
       "      <td>-9.42070</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54522</td>\n",
       "      <td>9.195642e-05</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.401254</td>\n",
       "      <td>-0.410987</td>\n",
       "      <td>-0.38221</td>\n",
       "      <td>-0.44605</td>\n",
       "      <td>9.935077e-05</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.597598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2.613423</td>\n",
       "      <td>2.6572</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.368746</td>\n",
       "      <td>-9.398851</td>\n",
       "      <td>-9.36570</td>\n",
       "      <td>-9.43560</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.55652</td>\n",
       "      <td>7.375030e-05</td>\n",
       "      <td>0.008588</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>-0.411248</td>\n",
       "      <td>-0.36581</td>\n",
       "      <td>-0.43676</td>\n",
       "      <td>8.659481e-05</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>1.021454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2.614750</td>\n",
       "      <td>2.6576</td>\n",
       "      <td>2.5654</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>-9.397350</td>\n",
       "      <td>-9.36280</td>\n",
       "      <td>-9.43130</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.53640</td>\n",
       "      <td>3.380089e-05</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-0.409787</td>\n",
       "      <td>-0.37926</td>\n",
       "      <td>-0.43431</td>\n",
       "      <td>7.258946e-05</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.431012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2.620167</td>\n",
       "      <td>2.6589</td>\n",
       "      <td>2.5781</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.114904</td>\n",
       "      <td>-9.397014</td>\n",
       "      <td>-9.36490</td>\n",
       "      <td>-9.45390</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54565</td>\n",
       "      <td>9.044032e-05</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>0.409508</td>\n",
       "      <td>-0.409101</td>\n",
       "      <td>-0.36074</td>\n",
       "      <td>-0.44087</td>\n",
       "      <td>1.127801e-04</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>1.368666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2.615565</td>\n",
       "      <td>2.6789</td>\n",
       "      <td>2.5734</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.608394</td>\n",
       "      <td>-9.398614</td>\n",
       "      <td>-9.36610</td>\n",
       "      <td>-9.42790</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.54256</td>\n",
       "      <td>9.748789e-05</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>0.413339</td>\n",
       "      <td>-0.410440</td>\n",
       "      <td>-0.38588</td>\n",
       "      <td>-0.43841</td>\n",
       "      <td>7.216993e-05</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.054973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "960     -4.834646     -4.7185     -4.9049    0.001124    0.033529   \n",
       "961     -4.780810     -4.5850     -4.8833    0.003948    0.062835   \n",
       "962     -4.804400     -4.7037     -4.8755    0.001482    0.038496   \n",
       "963     -4.750563     -4.5696     -4.8977    0.004447    0.066683   \n",
       "964     -4.774916     -4.6741     -4.8457    0.001080    0.032868   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "1915     2.620502      2.6592      2.5891    0.000199    0.014113   \n",
       "1916     2.613423      2.6572      2.5815    0.000207    0.014387   \n",
       "1917     2.614750      2.6576      2.5654    0.000257    0.016018   \n",
       "1918     2.620167      2.6589      2.5781    0.000216    0.014691   \n",
       "1919     2.615565      2.6789      2.5734    0.000310    0.017610   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "960      0.632141    -0.501018    -0.41744    -0.59561    0.001016  ...   \n",
       "961      1.052880    -0.480601    -0.40372    -0.63184    0.001297  ...   \n",
       "962      0.735226    -0.493925    -0.42616    -0.59561    0.000863  ...   \n",
       "963      0.710263    -0.437358    -0.30877    -0.55225    0.003587  ...   \n",
       "964      0.324779    -0.459456    -0.38900    -0.53714    0.001059  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "1915     0.148452    -9.392025    -9.34240    -9.42070    0.000242  ...   \n",
       "1916     0.368746    -9.398851    -9.36570    -9.43560    0.000156  ...   \n",
       "1917    -0.007991    -9.397350    -9.36280    -9.43130    0.000214  ...   \n",
       "1918    -0.114904    -9.397014    -9.36490    -9.45390    0.000257  ...   \n",
       "1919     0.608394    -9.398614    -9.36610    -9.42790    0.000167  ...   \n",
       "\n",
       "      LL_ymag_min   LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  \\\n",
       "960       0.56276  9.725263e-07     0.000986      0.074676     -0.532664   \n",
       "961       0.56394  6.211659e-07     0.000788     -0.181526     -0.531169   \n",
       "962       0.56445  4.579046e-07     0.000677     -0.263115     -0.530569   \n",
       "963       0.56420  4.703523e-07     0.000686     -0.060925     -0.531167   \n",
       "964       0.56455  5.467316e-07     0.000739      0.335811     -0.529804   \n",
       "...           ...           ...          ...           ...           ...   \n",
       "1915     -0.54522  9.195642e-05     0.009589      0.401254     -0.410987   \n",
       "1916     -0.55652  7.375030e-05     0.008588      0.147180     -0.411248   \n",
       "1917     -0.53640  3.380089e-05     0.005814      0.032341     -0.409787   \n",
       "1918     -0.54565  9.044032e-05     0.009510      0.409508     -0.409101   \n",
       "1919     -0.54256  9.748789e-05     0.009874      0.413339     -0.410440   \n",
       "\n",
       "      LL_zmag_max  LL_zmag_min   LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "960      -0.52993     -0.53521  9.585668e-07     0.000979     -0.193301  \n",
       "961      -0.52940     -0.53365  7.608973e-07     0.000872     -0.372381  \n",
       "962      -0.52873     -0.53222  5.160537e-07     0.000718      0.185587  \n",
       "963      -0.52962     -0.53283  4.975523e-07     0.000705     -0.145321  \n",
       "964      -0.52706     -0.53251  1.292131e-06     0.001137     -0.026271  \n",
       "...           ...          ...           ...          ...           ...  \n",
       "1915     -0.38221     -0.44605  9.935077e-05     0.009967     -0.597598  \n",
       "1916     -0.36581     -0.43676  8.659481e-05     0.009306      1.021454  \n",
       "1917     -0.37926     -0.43431  7.258946e-05     0.008520      0.431012  \n",
       "1918     -0.36074     -0.44087  1.127801e-04     0.010620      1.368666  \n",
       "1919     -0.38588     -0.43841  7.216993e-05     0.008495      0.054973  \n",
       "\n",
       "[960 rows x 270 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6c265bbc-11ec-41f2-b9eb-f7c5e9cf6659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.284643</td>\n",
       "      <td>-1.287445</td>\n",
       "      <td>-1.264521</td>\n",
       "      <td>-0.091235</td>\n",
       "      <td>-0.130391</td>\n",
       "      <td>1.293948</td>\n",
       "      <td>0.892481</td>\n",
       "      <td>0.886692</td>\n",
       "      <td>0.899934</td>\n",
       "      <td>-0.116043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741525</td>\n",
       "      <td>-0.141289</td>\n",
       "      <td>-0.293535</td>\n",
       "      <td>0.120756</td>\n",
       "      <td>-0.391035</td>\n",
       "      <td>-0.398140</td>\n",
       "      <td>-0.383163</td>\n",
       "      <td>-0.128573</td>\n",
       "      <td>-0.323099</td>\n",
       "      <td>-0.219429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.265346</td>\n",
       "      <td>-1.239346</td>\n",
       "      <td>-1.256829</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.480205</td>\n",
       "      <td>2.127967</td>\n",
       "      <td>0.897184</td>\n",
       "      <td>0.889847</td>\n",
       "      <td>0.891559</td>\n",
       "      <td>-0.100364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744028</td>\n",
       "      <td>-0.142472</td>\n",
       "      <td>-0.326798</td>\n",
       "      <td>-0.402114</td>\n",
       "      <td>-0.388128</td>\n",
       "      <td>-0.397107</td>\n",
       "      <td>-0.380127</td>\n",
       "      <td>-0.129875</td>\n",
       "      <td>-0.350275</td>\n",
       "      <td>-0.571525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.273802</td>\n",
       "      <td>-1.282112</td>\n",
       "      <td>-1.254051</td>\n",
       "      <td>-0.079420</td>\n",
       "      <td>-0.026906</td>\n",
       "      <td>1.498289</td>\n",
       "      <td>0.894115</td>\n",
       "      <td>0.884687</td>\n",
       "      <td>0.899934</td>\n",
       "      <td>-0.124633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745110</td>\n",
       "      <td>-0.143022</td>\n",
       "      <td>-0.345519</td>\n",
       "      <td>-0.568625</td>\n",
       "      <td>-0.386960</td>\n",
       "      <td>-0.395801</td>\n",
       "      <td>-0.377344</td>\n",
       "      <td>-0.131486</td>\n",
       "      <td>-0.389454</td>\n",
       "      <td>0.525521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.254504</td>\n",
       "      <td>-1.233798</td>\n",
       "      <td>-1.261957</td>\n",
       "      <td>0.018495</td>\n",
       "      <td>0.560377</td>\n",
       "      <td>1.448807</td>\n",
       "      <td>0.907144</td>\n",
       "      <td>0.911679</td>\n",
       "      <td>0.909958</td>\n",
       "      <td>0.027760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744580</td>\n",
       "      <td>-0.142980</td>\n",
       "      <td>-0.343984</td>\n",
       "      <td>-0.155985</td>\n",
       "      <td>-0.388123</td>\n",
       "      <td>-0.397536</td>\n",
       "      <td>-0.378531</td>\n",
       "      <td>-0.131608</td>\n",
       "      <td>-0.392762</td>\n",
       "      <td>-0.125092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.263233</td>\n",
       "      <td>-1.271448</td>\n",
       "      <td>-1.243439</td>\n",
       "      <td>-0.092685</td>\n",
       "      <td>-0.144164</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.902054</td>\n",
       "      <td>0.893231</td>\n",
       "      <td>0.913451</td>\n",
       "      <td>-0.113683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745322</td>\n",
       "      <td>-0.142723</td>\n",
       "      <td>-0.334982</td>\n",
       "      <td>0.653693</td>\n",
       "      <td>-0.385472</td>\n",
       "      <td>-0.392546</td>\n",
       "      <td>-0.377909</td>\n",
       "      <td>-0.126378</td>\n",
       "      <td>-0.282970</td>\n",
       "      <td>0.108977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>1.387633</td>\n",
       "      <td>1.370657</td>\n",
       "      <td>1.404301</td>\n",
       "      <td>-0.121786</td>\n",
       "      <td>-0.534929</td>\n",
       "      <td>0.335144</td>\n",
       "      <td>-1.155406</td>\n",
       "      <td>-1.165444</td>\n",
       "      <td>-1.140190</td>\n",
       "      <td>-0.159380</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.608766</td>\n",
       "      <td>0.165187</td>\n",
       "      <td>1.151541</td>\n",
       "      <td>0.787254</td>\n",
       "      <td>-0.154296</td>\n",
       "      <td>-0.110222</td>\n",
       "      <td>-0.209634</td>\n",
       "      <td>0.519106</td>\n",
       "      <td>1.964745</td>\n",
       "      <td>-1.014336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>1.385095</td>\n",
       "      <td>1.369937</td>\n",
       "      <td>1.401595</td>\n",
       "      <td>-0.121527</td>\n",
       "      <td>-0.529207</td>\n",
       "      <td>0.771827</td>\n",
       "      <td>-1.156979</td>\n",
       "      <td>-1.170801</td>\n",
       "      <td>-1.143635</td>\n",
       "      <td>-0.164200</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.632736</td>\n",
       "      <td>0.103861</td>\n",
       "      <td>0.983304</td>\n",
       "      <td>0.268727</td>\n",
       "      <td>-0.154805</td>\n",
       "      <td>-0.078257</td>\n",
       "      <td>-0.191553</td>\n",
       "      <td>0.435138</td>\n",
       "      <td>1.796282</td>\n",
       "      <td>2.168957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1.385571</td>\n",
       "      <td>1.370081</td>\n",
       "      <td>1.395861</td>\n",
       "      <td>-0.119890</td>\n",
       "      <td>-0.495238</td>\n",
       "      <td>0.025033</td>\n",
       "      <td>-1.156633</td>\n",
       "      <td>-1.170135</td>\n",
       "      <td>-1.142641</td>\n",
       "      <td>-0.160933</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.590056</td>\n",
       "      <td>-0.030708</td>\n",
       "      <td>0.517367</td>\n",
       "      <td>0.034356</td>\n",
       "      <td>-0.151962</td>\n",
       "      <td>-0.104472</td>\n",
       "      <td>-0.186785</td>\n",
       "      <td>0.342946</td>\n",
       "      <td>1.596299</td>\n",
       "      <td>1.008062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>1.387512</td>\n",
       "      <td>1.370549</td>\n",
       "      <td>1.400384</td>\n",
       "      <td>-0.121236</td>\n",
       "      <td>-0.522880</td>\n",
       "      <td>-0.186899</td>\n",
       "      <td>-1.156556</td>\n",
       "      <td>-1.170617</td>\n",
       "      <td>-1.147865</td>\n",
       "      <td>-0.158533</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.609678</td>\n",
       "      <td>0.160080</td>\n",
       "      <td>1.138208</td>\n",
       "      <td>0.804099</td>\n",
       "      <td>-0.150627</td>\n",
       "      <td>-0.068375</td>\n",
       "      <td>-0.199553</td>\n",
       "      <td>0.607507</td>\n",
       "      <td>2.130780</td>\n",
       "      <td>2.851627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>1.385863</td>\n",
       "      <td>1.377755</td>\n",
       "      <td>1.398710</td>\n",
       "      <td>-0.118122</td>\n",
       "      <td>-0.462074</td>\n",
       "      <td>1.246874</td>\n",
       "      <td>-1.156924</td>\n",
       "      <td>-1.170893</td>\n",
       "      <td>-1.141855</td>\n",
       "      <td>-0.163569</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.603123</td>\n",
       "      <td>0.183820</td>\n",
       "      <td>1.199279</td>\n",
       "      <td>0.811918</td>\n",
       "      <td>-0.153232</td>\n",
       "      <td>-0.117375</td>\n",
       "      <td>-0.194765</td>\n",
       "      <td>0.340185</td>\n",
       "      <td>1.590023</td>\n",
       "      <td>0.268714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "0      -1.284643   -1.287445   -1.264521   -0.091235   -0.130391     1.293948   \n",
       "1      -1.265346   -1.239346   -1.256829    0.002035    0.480205     2.127967   \n",
       "2      -1.273802   -1.282112   -1.254051   -0.079420   -0.026906     1.498289   \n",
       "3      -1.254504   -1.233798   -1.261957    0.018495    0.560377     1.448807   \n",
       "4      -1.263233   -1.271448   -1.243439   -0.092685   -0.144164     0.684672   \n",
       "..           ...         ...         ...         ...         ...          ...   \n",
       "955     1.387633    1.370657    1.404301   -0.121786   -0.534929     0.335144   \n",
       "956     1.385095    1.369937    1.401595   -0.121527   -0.529207     0.771827   \n",
       "957     1.385571    1.370081    1.395861   -0.119890   -0.495238     0.025033   \n",
       "958     1.387512    1.370549    1.400384   -0.121236   -0.522880    -0.186899   \n",
       "959     1.385863    1.377755    1.398710   -0.118122   -0.462074     1.246874   \n",
       "\n",
       "     T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  LL_ymag_min  \\\n",
       "0       0.892481    0.886692    0.899934   -0.116043  ...     0.741525   \n",
       "1       0.897184    0.889847    0.891559   -0.100364  ...     0.744028   \n",
       "2       0.894115    0.884687    0.899934   -0.124633  ...     0.745110   \n",
       "3       0.907144    0.911679    0.909958    0.027760  ...     0.744580   \n",
       "4       0.902054    0.893231    0.913451   -0.113683  ...     0.745322   \n",
       "..           ...         ...         ...         ...  ...          ...   \n",
       "955    -1.155406   -1.165444   -1.140190   -0.159380  ...    -1.608766   \n",
       "956    -1.156979   -1.170801   -1.143635   -0.164200  ...    -1.632736   \n",
       "957    -1.156633   -1.170135   -1.142641   -0.160933  ...    -1.590056   \n",
       "958    -1.156556   -1.170617   -1.147865   -0.158533  ...    -1.609678   \n",
       "959    -1.156924   -1.170893   -1.141855   -0.163569  ...    -1.603123   \n",
       "\n",
       "     LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  \\\n",
       "0      -0.141289    -0.293535      0.120756     -0.391035    -0.398140   \n",
       "1      -0.142472    -0.326798     -0.402114     -0.388128    -0.397107   \n",
       "2      -0.143022    -0.345519     -0.568625     -0.386960    -0.395801   \n",
       "3      -0.142980    -0.343984     -0.155985     -0.388123    -0.397536   \n",
       "4      -0.142723    -0.334982      0.653693     -0.385472    -0.392546   \n",
       "..           ...          ...           ...           ...          ...   \n",
       "955     0.165187     1.151541      0.787254     -0.154296    -0.110222   \n",
       "956     0.103861     0.983304      0.268727     -0.154805    -0.078257   \n",
       "957    -0.030708     0.517367      0.034356     -0.151962    -0.104472   \n",
       "958     0.160080     1.138208      0.804099     -0.150627    -0.068375   \n",
       "959     0.183820     1.199279      0.811918     -0.153232    -0.117375   \n",
       "\n",
       "     LL_zmag_min  LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "0      -0.383163    -0.128573    -0.323099     -0.219429  \n",
       "1      -0.380127    -0.129875    -0.350275     -0.571525  \n",
       "2      -0.377344    -0.131486    -0.389454      0.525521  \n",
       "3      -0.378531    -0.131608    -0.392762     -0.125092  \n",
       "4      -0.377909    -0.126378    -0.282970      0.108977  \n",
       "..           ...          ...          ...           ...  \n",
       "955    -0.209634     0.519106     1.964745     -1.014336  \n",
       "956    -0.191553     0.435138     1.796282      2.168957  \n",
       "957    -0.186785     0.342946     1.596299      1.008062  \n",
       "958    -0.199553     0.607507     2.130780      2.851627  \n",
       "959    -0.194765     0.340185     1.590023      0.268714  \n",
       "\n",
       "[960 rows x 270 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 가정: X_test는 이미 정의된 데이터프레임입니다.\n",
    "\n",
    "# 'activity', 'people', 'Class' 열을 제외한 데이터만 추출하여 스케일링\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X_train)\n",
    "\n",
    "# 스케일링된 데이터를 DataFrame으로 변환\n",
    "scaled_X_train = pd.DataFrame(scaled_features, columns=X_train.columns)\n",
    "\n",
    "# 결과 출력\n",
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f9a20a0-2c47-4125-ba45-66aa6db93810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_min</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.245884</td>\n",
       "      <td>1.377348</td>\n",
       "      <td>-0.501758</td>\n",
       "      <td>1.086338</td>\n",
       "      <td>1.360408</td>\n",
       "      <td>0.722969</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>1.085533</td>\n",
       "      <td>-0.340741</td>\n",
       "      <td>0.024398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.245923</td>\n",
       "      <td>0.178284</td>\n",
       "      <td>0.762128</td>\n",
       "      <td>-0.177939</td>\n",
       "      <td>-0.506292</td>\n",
       "      <td>-0.498646</td>\n",
       "      <td>-0.528797</td>\n",
       "      <td>-0.180767</td>\n",
       "      <td>0.119373</td>\n",
       "      <td>0.049311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.238364</td>\n",
       "      <td>1.374750</td>\n",
       "      <td>-0.843667</td>\n",
       "      <td>0.952412</td>\n",
       "      <td>1.277344</td>\n",
       "      <td>0.534648</td>\n",
       "      <td>0.827096</td>\n",
       "      <td>0.797479</td>\n",
       "      <td>0.065043</td>\n",
       "      <td>-0.089578</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083568</td>\n",
       "      <td>-0.065630</td>\n",
       "      <td>0.429245</td>\n",
       "      <td>1.033077</td>\n",
       "      <td>-0.470510</td>\n",
       "      <td>-0.454645</td>\n",
       "      <td>-0.495151</td>\n",
       "      <td>-0.190747</td>\n",
       "      <td>0.086673</td>\n",
       "      <td>0.154914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.300596</td>\n",
       "      <td>1.463733</td>\n",
       "      <td>-0.397015</td>\n",
       "      <td>1.242005</td>\n",
       "      <td>1.452885</td>\n",
       "      <td>0.857697</td>\n",
       "      <td>0.846208</td>\n",
       "      <td>0.862238</td>\n",
       "      <td>-0.228920</td>\n",
       "      <td>-0.023104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022694</td>\n",
       "      <td>-0.063276</td>\n",
       "      <td>0.432933</td>\n",
       "      <td>0.833026</td>\n",
       "      <td>-0.414757</td>\n",
       "      <td>-0.348399</td>\n",
       "      <td>-0.461003</td>\n",
       "      <td>-0.102096</td>\n",
       "      <td>0.338334</td>\n",
       "      <td>0.412423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.187154</td>\n",
       "      <td>1.453830</td>\n",
       "      <td>-1.106765</td>\n",
       "      <td>1.345335</td>\n",
       "      <td>1.512112</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>0.798947</td>\n",
       "      <td>1.016988</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>-0.051653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039301</td>\n",
       "      <td>-0.156206</td>\n",
       "      <td>0.276678</td>\n",
       "      <td>0.528352</td>\n",
       "      <td>-0.348662</td>\n",
       "      <td>-0.331746</td>\n",
       "      <td>-0.397832</td>\n",
       "      <td>-0.140601</td>\n",
       "      <td>0.238283</td>\n",
       "      <td>-0.544319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.342854</td>\n",
       "      <td>1.533792</td>\n",
       "      <td>-0.742701</td>\n",
       "      <td>1.410346</td>\n",
       "      <td>1.548566</td>\n",
       "      <td>0.803560</td>\n",
       "      <td>0.861764</td>\n",
       "      <td>0.979432</td>\n",
       "      <td>-0.343021</td>\n",
       "      <td>0.099105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098156</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>0.581708</td>\n",
       "      <td>0.475541</td>\n",
       "      <td>-0.407439</td>\n",
       "      <td>-0.364552</td>\n",
       "      <td>-0.435619</td>\n",
       "      <td>-0.187520</td>\n",
       "      <td>0.097414</td>\n",
       "      <td>0.939220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0.073706</td>\n",
       "      <td>-0.480105</td>\n",
       "      <td>1.455277</td>\n",
       "      <td>-0.588456</td>\n",
       "      <td>-0.672206</td>\n",
       "      <td>-0.193505</td>\n",
       "      <td>-1.562998</td>\n",
       "      <td>-1.373423</td>\n",
       "      <td>-0.780094</td>\n",
       "      <td>-0.504844</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.530519</td>\n",
       "      <td>-0.378513</td>\n",
       "      <td>-0.301860</td>\n",
       "      <td>0.630753</td>\n",
       "      <td>-0.427383</td>\n",
       "      <td>-0.421302</td>\n",
       "      <td>-0.451181</td>\n",
       "      <td>-0.251048</td>\n",
       "      <td>-0.159130</td>\n",
       "      <td>-1.035369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.072400</td>\n",
       "      <td>-0.480203</td>\n",
       "      <td>1.453412</td>\n",
       "      <td>-0.588456</td>\n",
       "      <td>-0.672157</td>\n",
       "      <td>0.165390</td>\n",
       "      <td>-1.564741</td>\n",
       "      <td>-1.377526</td>\n",
       "      <td>-0.783298</td>\n",
       "      <td>-0.504868</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.556611</td>\n",
       "      <td>-0.386765</td>\n",
       "      <td>-0.341703</td>\n",
       "      <td>0.081878</td>\n",
       "      <td>-0.427877</td>\n",
       "      <td>-0.390957</td>\n",
       "      <td>-0.433289</td>\n",
       "      <td>-0.256580</td>\n",
       "      <td>-0.188857</td>\n",
       "      <td>1.751360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.072645</td>\n",
       "      <td>-0.480183</td>\n",
       "      <td>1.449462</td>\n",
       "      <td>-0.588455</td>\n",
       "      <td>-0.671870</td>\n",
       "      <td>-0.448374</td>\n",
       "      <td>-1.564358</td>\n",
       "      <td>-1.377015</td>\n",
       "      <td>-0.782373</td>\n",
       "      <td>-0.504851</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.510154</td>\n",
       "      <td>-0.404874</td>\n",
       "      <td>-0.452051</td>\n",
       "      <td>-0.166210</td>\n",
       "      <td>-0.425115</td>\n",
       "      <td>-0.415844</td>\n",
       "      <td>-0.428570</td>\n",
       "      <td>-0.262653</td>\n",
       "      <td>-0.224145</td>\n",
       "      <td>0.735085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0.073644</td>\n",
       "      <td>-0.480119</td>\n",
       "      <td>1.452578</td>\n",
       "      <td>-0.588456</td>\n",
       "      <td>-0.672104</td>\n",
       "      <td>-0.622553</td>\n",
       "      <td>-1.564272</td>\n",
       "      <td>-1.377385</td>\n",
       "      <td>-0.787233</td>\n",
       "      <td>-0.504839</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.531512</td>\n",
       "      <td>-0.379200</td>\n",
       "      <td>-0.305018</td>\n",
       "      <td>0.648584</td>\n",
       "      <td>-0.423819</td>\n",
       "      <td>-0.381575</td>\n",
       "      <td>-0.441204</td>\n",
       "      <td>-0.245224</td>\n",
       "      <td>-0.129832</td>\n",
       "      <td>2.348985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.072795</td>\n",
       "      <td>-0.479139</td>\n",
       "      <td>1.451424</td>\n",
       "      <td>-0.588455</td>\n",
       "      <td>-0.671589</td>\n",
       "      <td>0.555814</td>\n",
       "      <td>-1.564681</td>\n",
       "      <td>-1.377596</td>\n",
       "      <td>-0.781642</td>\n",
       "      <td>-0.504864</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.524377</td>\n",
       "      <td>-0.376005</td>\n",
       "      <td>-0.290554</td>\n",
       "      <td>0.656861</td>\n",
       "      <td>-0.426349</td>\n",
       "      <td>-0.428093</td>\n",
       "      <td>-0.436466</td>\n",
       "      <td>-0.262835</td>\n",
       "      <td>-0.225253</td>\n",
       "      <td>0.087842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 270 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        1.245884    1.377348   -0.501758    1.086338    1.360408   \n",
       "1        1.238364    1.374750   -0.843667    0.952412    1.277344   \n",
       "2        1.300596    1.463733   -0.397015    1.242005    1.452885   \n",
       "3        1.187154    1.453830   -1.106765    1.345335    1.512112   \n",
       "4        1.342854    1.533792   -0.742701    1.410346    1.548566   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "1435     0.073706   -0.480105    1.455277   -0.588456   -0.672206   \n",
       "1436     0.072400   -0.480203    1.453412   -0.588456   -0.672157   \n",
       "1437     0.072645   -0.480183    1.449462   -0.588455   -0.671870   \n",
       "1438     0.073644   -0.480119    1.452578   -0.588456   -0.672104   \n",
       "1439     0.072795   -0.479139    1.451424   -0.588455   -0.671589   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0        0.722969     0.827854    1.085533   -0.340741    0.024398  ...   \n",
       "1        0.534648     0.827096    0.797479    0.065043   -0.089578  ...   \n",
       "2        0.857697     0.846208    0.862238   -0.228920   -0.023104  ...   \n",
       "3        1.050900     0.798947    1.016988    0.014229   -0.051653  ...   \n",
       "4        0.803560     0.861764    0.979432   -0.343021    0.099105  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "1435    -0.193505    -1.562998   -1.373423   -0.780094   -0.504844  ...   \n",
       "1436     0.165390    -1.564741   -1.377526   -0.783298   -0.504868  ...   \n",
       "1437    -0.448374    -1.564358   -1.377015   -0.782373   -0.504851  ...   \n",
       "1438    -0.622553    -1.564272   -1.377385   -0.787233   -0.504839  ...   \n",
       "1439     0.555814    -1.564681   -1.377596   -0.781642   -0.504864  ...   \n",
       "\n",
       "      LL_ymag_min  LL_ymag_var  LL_ymag_std  LL_ymag_skew  LL_zmag_mean  \\\n",
       "0       -0.245923     0.178284     0.762128     -0.177939     -0.506292   \n",
       "1       -0.083568    -0.065630     0.429245      1.033077     -0.470510   \n",
       "2       -0.022694    -0.063276     0.432933      0.833026     -0.414757   \n",
       "3        0.039301    -0.156206     0.276678      0.528352     -0.348662   \n",
       "4       -0.098156     0.038205     0.581708      0.475541     -0.407439   \n",
       "...           ...          ...          ...           ...           ...   \n",
       "1435    -1.530519    -0.378513    -0.301860      0.630753     -0.427383   \n",
       "1436    -1.556611    -0.386765    -0.341703      0.081878     -0.427877   \n",
       "1437    -1.510154    -0.404874    -0.452051     -0.166210     -0.425115   \n",
       "1438    -1.531512    -0.379200    -0.305018      0.648584     -0.423819   \n",
       "1439    -1.524377    -0.376005    -0.290554      0.656861     -0.426349   \n",
       "\n",
       "      LL_zmag_max  LL_zmag_min  LL_zmag_var  LL_zmag_std  LL_zmag_skew  \n",
       "0       -0.498646    -0.528797    -0.180767     0.119373      0.049311  \n",
       "1       -0.454645    -0.495151    -0.190747     0.086673      0.154914  \n",
       "2       -0.348399    -0.461003    -0.102096     0.338334      0.412423  \n",
       "3       -0.331746    -0.397832    -0.140601     0.238283     -0.544319  \n",
       "4       -0.364552    -0.435619    -0.187520     0.097414      0.939220  \n",
       "...           ...          ...          ...          ...           ...  \n",
       "1435    -0.421302    -0.451181    -0.251048    -0.159130     -1.035369  \n",
       "1436    -0.390957    -0.433289    -0.256580    -0.188857      1.751360  \n",
       "1437    -0.415844    -0.428570    -0.262653    -0.224145      0.735085  \n",
       "1438    -0.381575    -0.441204    -0.245224    -0.129832      2.348985  \n",
       "1439    -0.428093    -0.436466    -0.262835    -0.225253      0.087842  \n",
       "\n",
       "[1440 rows x 270 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 가정: X_test는 이미 정의된 데이터프레임입니다.\n",
    "\n",
    "# 'activity', 'people', 'Class' 열을 제외한 데이터만 추출하여 스케일링\n",
    "features = X_test.drop(['activity', 'people', 'Class'], axis=1)\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# 스케일링된 데이터를 DataFrame으로 변환\n",
    "scaled_X_test = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "\n",
    "# 결과 출력\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ff619ca-0283-4ac9-8051-e87468a9fee3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>8.978253</td>\n",
       "      <td>40.5460</td>\n",
       "      <td>-5.3871</td>\n",
       "      <td>133.210928</td>\n",
       "      <td>11.541704</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>-0.028485</td>\n",
       "      <td>4.6232</td>\n",
       "      <td>-7.3776</td>\n",
       "      <td>1.913818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>-0.452746</td>\n",
       "      <td>-0.42401</td>\n",
       "      <td>-0.48635</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>8.937468</td>\n",
       "      <td>40.4930</td>\n",
       "      <td>-6.7806</td>\n",
       "      <td>122.558637</td>\n",
       "      <td>11.070620</td>\n",
       "      <td>0.595402</td>\n",
       "      <td>-0.031455</td>\n",
       "      <td>2.9872</td>\n",
       "      <td>-5.4906</td>\n",
       "      <td>1.501715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587490</td>\n",
       "      <td>-0.433809</td>\n",
       "      <td>-0.40023</td>\n",
       "      <td>-0.46888</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.093940</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>9.275007</td>\n",
       "      <td>42.3080</td>\n",
       "      <td>-4.9602</td>\n",
       "      <td>145.592435</td>\n",
       "      <td>12.066169</td>\n",
       "      <td>0.793694</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>3.3550</td>\n",
       "      <td>-6.8576</td>\n",
       "      <td>1.742066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494886</td>\n",
       "      <td>-0.404305</td>\n",
       "      <td>-0.34281</td>\n",
       "      <td>-0.45115</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.243550</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>8.659709</td>\n",
       "      <td>42.1060</td>\n",
       "      <td>-7.8529</td>\n",
       "      <td>153.811145</td>\n",
       "      <td>12.402062</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>-0.141696</td>\n",
       "      <td>4.2339</td>\n",
       "      <td>-5.7269</td>\n",
       "      <td>1.638842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353853</td>\n",
       "      <td>-0.369328</td>\n",
       "      <td>-0.33381</td>\n",
       "      <td>-0.41835</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>-0.312305</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>9.504206</td>\n",
       "      <td>43.7370</td>\n",
       "      <td>-6.3691</td>\n",
       "      <td>158.982033</td>\n",
       "      <td>12.608808</td>\n",
       "      <td>0.760463</td>\n",
       "      <td>0.104321</td>\n",
       "      <td>4.0206</td>\n",
       "      <td>-7.3882</td>\n",
       "      <td>2.183937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>-0.400433</td>\n",
       "      <td>-0.35154</td>\n",
       "      <td>-0.43797</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.549612</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2.620502</td>\n",
       "      <td>2.6592</td>\n",
       "      <td>2.5891</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>-9.392025</td>\n",
       "      <td>-9.3424</td>\n",
       "      <td>-9.4207</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401254</td>\n",
       "      <td>-0.410987</td>\n",
       "      <td>-0.38221</td>\n",
       "      <td>-0.44605</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.597598</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2.613423</td>\n",
       "      <td>2.6572</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.368746</td>\n",
       "      <td>-9.398851</td>\n",
       "      <td>-9.3657</td>\n",
       "      <td>-9.4356</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>-0.411248</td>\n",
       "      <td>-0.36581</td>\n",
       "      <td>-0.43676</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>1.021454</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2.614750</td>\n",
       "      <td>2.6576</td>\n",
       "      <td>2.5654</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>-9.397350</td>\n",
       "      <td>-9.3628</td>\n",
       "      <td>-9.4313</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-0.409787</td>\n",
       "      <td>-0.37926</td>\n",
       "      <td>-0.43431</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.431012</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2.620167</td>\n",
       "      <td>2.6589</td>\n",
       "      <td>2.5781</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.114904</td>\n",
       "      <td>-9.397014</td>\n",
       "      <td>-9.3649</td>\n",
       "      <td>-9.4539</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409508</td>\n",
       "      <td>-0.409101</td>\n",
       "      <td>-0.36074</td>\n",
       "      <td>-0.44087</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>1.368666</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2.615565</td>\n",
       "      <td>2.6789</td>\n",
       "      <td>2.5734</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.608394</td>\n",
       "      <td>-9.398614</td>\n",
       "      <td>-9.3661</td>\n",
       "      <td>-9.4279</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413339</td>\n",
       "      <td>-0.410440</td>\n",
       "      <td>-0.38588</td>\n",
       "      <td>-0.43841</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "8160     8.978253     40.5460     -5.3871  133.210928   11.541704   \n",
       "8161     8.937468     40.4930     -6.7806  122.558637   11.070620   \n",
       "8162     9.275007     42.3080     -4.9602  145.592435   12.066169   \n",
       "8163     8.659709     42.1060     -7.8529  153.811145   12.402062   \n",
       "8164     9.504206     43.7370     -6.3691  158.982033   12.608808   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "1915     2.620502      2.6592      2.5891    0.000199    0.014113   \n",
       "1916     2.613423      2.6572      2.5815    0.000207    0.014387   \n",
       "1917     2.614750      2.6576      2.5654    0.000257    0.016018   \n",
       "1918     2.620167      2.6589      2.5781    0.000216    0.014691   \n",
       "1919     2.615565      2.6789      2.5734    0.000310    0.017610   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "8160     0.710995    -0.028485      4.6232     -7.3776    1.913818  ...   \n",
       "8161     0.595402    -0.031455      2.9872     -5.4906    1.501715  ...   \n",
       "8162     0.793694     0.043397      3.3550     -6.8576    1.742066  ...   \n",
       "8163     0.912284    -0.141696      4.2339     -5.7269    1.638842  ...   \n",
       "8164     0.760463     0.104321      4.0206     -7.3882    2.183937  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "1915     0.148452    -9.392025     -9.3424     -9.4207    0.000242  ...   \n",
       "1916     0.368746    -9.398851     -9.3657     -9.4356    0.000156  ...   \n",
       "1917    -0.007991    -9.397350     -9.3628     -9.4313    0.000214  ...   \n",
       "1918    -0.114904    -9.397014     -9.3649     -9.4539    0.000257  ...   \n",
       "1919     0.608394    -9.398614     -9.3661     -9.4279    0.000167  ...   \n",
       "\n",
       "      LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  LL_zmag_var  \\\n",
       "8160      0.026911     -0.452746     -0.42401     -0.48635     0.000261   \n",
       "8161      0.587490     -0.433809     -0.40023     -0.46888     0.000238   \n",
       "8162      0.494886     -0.404305     -0.34281     -0.45115     0.000443   \n",
       "8163      0.353853     -0.369328     -0.33381     -0.41835     0.000354   \n",
       "8164      0.329407     -0.400433     -0.35154     -0.43797     0.000246   \n",
       "...            ...           ...          ...          ...          ...   \n",
       "1915      0.401254     -0.410987     -0.38221     -0.44605     0.000099   \n",
       "1916      0.147180     -0.411248     -0.36581     -0.43676     0.000087   \n",
       "1917      0.032341     -0.409787     -0.37926     -0.43431     0.000073   \n",
       "1918      0.409508     -0.409101     -0.36074     -0.44087     0.000113   \n",
       "1919      0.413339     -0.410440     -0.38588     -0.43841     0.000072   \n",
       "\n",
       "      LL_zmag_std  LL_zmag_skew   activity  people  Class  \n",
       "8160     0.016168      0.032586    jumping      p1    1.0  \n",
       "8161     0.015440      0.093940    jumping      p1    1.0  \n",
       "8162     0.021043      0.243550    jumping      p1    1.0  \n",
       "8163     0.018816     -0.312305    jumping      p1    1.0  \n",
       "8164     0.015679      0.549612    jumping      p1    1.0  \n",
       "...           ...           ...        ...     ...    ...  \n",
       "1915     0.009967     -0.597598  lyingRigh      p8    0.0  \n",
       "1916     0.009306      1.021454  lyingRigh      p8    0.0  \n",
       "1917     0.008520      0.431012  lyingRigh      p8    0.0  \n",
       "1918     0.010620      1.368666  lyingRigh      p8    0.0  \n",
       "1919     0.008495      0.054973  lyingRigh      p8    0.0  \n",
       "\n",
       "[1440 rows x 273 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d2c5b7f6-83e0-4334-b77e-15084f9076b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 270)]             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 14)                3794      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 7)                 105       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 7)                 56        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 270)               2160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,115\n",
      "Trainable params: 6,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 입력 데이터의 차원 수를 정의합니다. X_train의 열 개수와 동일하게 설정합니다.\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# 인코딩 차원 수를 설정합니다. 이는 잠재 공간(latent space)의 크기이며, 원하는 값으로 조정할 수 있습니다.\n",
    "encoding_dim = 14  # 압축할 차원의 크기\n",
    "\n",
    "# 입력 레이어를 정의합니다. 입력 데이터의 형태를 지정합니다.\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "\n",
    "# 인코딩 과정: 입력 레이어에서 14개의 뉴런을 가진 은닉층으로 압축합니다.\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "\n",
    "# 인코딩된 값을 절반 크기의 은닉층으로 한 번 더 압축합니다.\n",
    "encoded = Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "\n",
    "# 디코딩 과정: 인코딩된 값을 다시 원래 차원의 절반 크기 은닉층으로 복원합니다.\n",
    "decoded = Dense(int(encoding_dim / 2), activation='relu')(encoded)\n",
    "\n",
    "# 원래 입력 차원 크기로 복원하는 출력 레이어를 정의합니다.\n",
    "# 출력값은 0과 1 사이로 제한하기 위해 'sigmoid' 활성화 함수를 사용합니다.\n",
    "decoded = Dense(input_dim, activation='sigmoid')(decoded)\n",
    "\n",
    "# 입력 레이어와 출력 레이어를 연결하여 오토인코더 모델을 생성합니다.\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "\n",
    "# 오토인코더 모델을 컴파일합니다.\n",
    "# Adam 옵티마이저를 사용하며, 학습률(learning_rate)은 0.001로 설정합니다.\n",
    "# 손실 함수로 평균 제곱 오차(mse)를 사용하여 입력과 출력 간의 차이를 최소화합니다.\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# 모델의 요약 정보를 출력하여 모델 구조를 확인합니다.\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df078bdb-5874-4580-8036-56e78856638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 5.8575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 10:03:19.200213: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 73ms/step - loss: 5.7634 - val_loss: 5.6418\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 5.7419 - val_loss: 5.6247\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.7182 - val_loss: 5.6026\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6886 - val_loss: 5.5753\n",
      "Epoch 5/50\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 5.5874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 10:03:19.514039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step - loss: 5.6487 - val_loss: 5.5401\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5961 - val_loss: 5.4981\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.5341 - val_loss: 5.4501\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.4651 - val_loss: 5.3972\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3929 - val_loss: 5.3413\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.3219 - val_loss: 5.2851\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.2550 - val_loss: 5.2305\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1967 - val_loss: 5.1798\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1477 - val_loss: 5.1341\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1082 - val_loss: 5.0949\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0779 - val_loss: 5.0616\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0562 - val_loss: 5.0357\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0414 - val_loss: 5.0180\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0311 - val_loss: 5.0065\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.0231 - val_loss: 4.9996\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0158 - val_loss: 4.9948\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0089 - val_loss: 4.9897\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5.0018 - val_loss: 4.9828\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9949 - val_loss: 4.9745\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9883 - val_loss: 4.9672\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9822 - val_loss: 4.9626\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9766 - val_loss: 4.9596\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9717 - val_loss: 4.9578\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9676 - val_loss: 4.9571\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9643 - val_loss: 4.9569\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9617 - val_loss: 4.9570\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9595 - val_loss: 4.9571\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9576 - val_loss: 4.9575\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9559 - val_loss: 4.9583\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9544 - val_loss: 4.9594\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9532 - val_loss: 4.9606\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9521 - val_loss: 4.9614\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9510 - val_loss: 4.9622\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9501 - val_loss: 4.9629\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9494 - val_loss: 4.9634\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9487 - val_loss: 4.9635\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9481 - val_loss: 4.9635\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9476 - val_loss: 4.9633\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9470 - val_loss: 4.9630\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9463 - val_loss: 4.9626\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9456 - val_loss: 4.9620\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 4.9445 - val_loss: 4.9614\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9430 - val_loss: 4.9617\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 4.9410 - val_loss: 4.9632\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9392 - val_loss: 4.9643\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 4.9382 - val_loss: 4.9642\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터의 0.1 을 validation data로 사용\n",
    "history = autoencoder.fit(X_train,X_train, \n",
    "                          epochs=50, \n",
    "                          batch_size=256, \n",
    "                          shuffle=True, \n",
    "                          validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1ca9da7d-bc11-4675-9df5-8dc9f3a7a26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6421eb9f-c575-4092-965d-a48e486e8665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8160</th>\n",
       "      <td>8.978253</td>\n",
       "      <td>40.5460</td>\n",
       "      <td>-5.3871</td>\n",
       "      <td>133.210928</td>\n",
       "      <td>11.541704</td>\n",
       "      <td>0.710995</td>\n",
       "      <td>-0.028485</td>\n",
       "      <td>4.6232</td>\n",
       "      <td>-7.3776</td>\n",
       "      <td>1.913818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026911</td>\n",
       "      <td>-0.452746</td>\n",
       "      <td>-0.42401</td>\n",
       "      <td>-0.48635</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.032586</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8161</th>\n",
       "      <td>8.937468</td>\n",
       "      <td>40.4930</td>\n",
       "      <td>-6.7806</td>\n",
       "      <td>122.558637</td>\n",
       "      <td>11.070620</td>\n",
       "      <td>0.595402</td>\n",
       "      <td>-0.031455</td>\n",
       "      <td>2.9872</td>\n",
       "      <td>-5.4906</td>\n",
       "      <td>1.501715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587490</td>\n",
       "      <td>-0.433809</td>\n",
       "      <td>-0.40023</td>\n",
       "      <td>-0.46888</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.015440</td>\n",
       "      <td>0.093940</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8162</th>\n",
       "      <td>9.275007</td>\n",
       "      <td>42.3080</td>\n",
       "      <td>-4.9602</td>\n",
       "      <td>145.592435</td>\n",
       "      <td>12.066169</td>\n",
       "      <td>0.793694</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>3.3550</td>\n",
       "      <td>-6.8576</td>\n",
       "      <td>1.742066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494886</td>\n",
       "      <td>-0.404305</td>\n",
       "      <td>-0.34281</td>\n",
       "      <td>-0.45115</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.021043</td>\n",
       "      <td>0.243550</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8163</th>\n",
       "      <td>8.659709</td>\n",
       "      <td>42.1060</td>\n",
       "      <td>-7.8529</td>\n",
       "      <td>153.811145</td>\n",
       "      <td>12.402062</td>\n",
       "      <td>0.912284</td>\n",
       "      <td>-0.141696</td>\n",
       "      <td>4.2339</td>\n",
       "      <td>-5.7269</td>\n",
       "      <td>1.638842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353853</td>\n",
       "      <td>-0.369328</td>\n",
       "      <td>-0.33381</td>\n",
       "      <td>-0.41835</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.018816</td>\n",
       "      <td>-0.312305</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>9.504206</td>\n",
       "      <td>43.7370</td>\n",
       "      <td>-6.3691</td>\n",
       "      <td>158.982033</td>\n",
       "      <td>12.608808</td>\n",
       "      <td>0.760463</td>\n",
       "      <td>0.104321</td>\n",
       "      <td>4.0206</td>\n",
       "      <td>-7.3882</td>\n",
       "      <td>2.183937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329407</td>\n",
       "      <td>-0.400433</td>\n",
       "      <td>-0.35154</td>\n",
       "      <td>-0.43797</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.549612</td>\n",
       "      <td>jumping</td>\n",
       "      <td>p1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>2.620502</td>\n",
       "      <td>2.6592</td>\n",
       "      <td>2.5891</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.014113</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>-9.392025</td>\n",
       "      <td>-9.3424</td>\n",
       "      <td>-9.4207</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401254</td>\n",
       "      <td>-0.410987</td>\n",
       "      <td>-0.38221</td>\n",
       "      <td>-0.44605</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.597598</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>2.613423</td>\n",
       "      <td>2.6572</td>\n",
       "      <td>2.5815</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.368746</td>\n",
       "      <td>-9.398851</td>\n",
       "      <td>-9.3657</td>\n",
       "      <td>-9.4356</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147180</td>\n",
       "      <td>-0.411248</td>\n",
       "      <td>-0.36581</td>\n",
       "      <td>-0.43676</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>1.021454</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2.614750</td>\n",
       "      <td>2.6576</td>\n",
       "      <td>2.5654</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>-0.007991</td>\n",
       "      <td>-9.397350</td>\n",
       "      <td>-9.3628</td>\n",
       "      <td>-9.4313</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-0.409787</td>\n",
       "      <td>-0.37926</td>\n",
       "      <td>-0.43431</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.431012</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>2.620167</td>\n",
       "      <td>2.6589</td>\n",
       "      <td>2.5781</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>-0.114904</td>\n",
       "      <td>-9.397014</td>\n",
       "      <td>-9.3649</td>\n",
       "      <td>-9.4539</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409508</td>\n",
       "      <td>-0.409101</td>\n",
       "      <td>-0.36074</td>\n",
       "      <td>-0.44087</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>1.368666</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>2.615565</td>\n",
       "      <td>2.6789</td>\n",
       "      <td>2.5734</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.017610</td>\n",
       "      <td>0.608394</td>\n",
       "      <td>-9.398614</td>\n",
       "      <td>-9.3661</td>\n",
       "      <td>-9.4279</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413339</td>\n",
       "      <td>-0.410440</td>\n",
       "      <td>-0.38588</td>\n",
       "      <td>-0.43841</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.054973</td>\n",
       "      <td>lyingRigh</td>\n",
       "      <td>p8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "8160     8.978253     40.5460     -5.3871  133.210928   11.541704   \n",
       "8161     8.937468     40.4930     -6.7806  122.558637   11.070620   \n",
       "8162     9.275007     42.3080     -4.9602  145.592435   12.066169   \n",
       "8163     8.659709     42.1060     -7.8529  153.811145   12.402062   \n",
       "8164     9.504206     43.7370     -6.3691  158.982033   12.608808   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "1915     2.620502      2.6592      2.5891    0.000199    0.014113   \n",
       "1916     2.613423      2.6572      2.5815    0.000207    0.014387   \n",
       "1917     2.614750      2.6576      2.5654    0.000257    0.016018   \n",
       "1918     2.620167      2.6589      2.5781    0.000216    0.014691   \n",
       "1919     2.615565      2.6789      2.5734    0.000310    0.017610   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "8160     0.710995    -0.028485      4.6232     -7.3776    1.913818  ...   \n",
       "8161     0.595402    -0.031455      2.9872     -5.4906    1.501715  ...   \n",
       "8162     0.793694     0.043397      3.3550     -6.8576    1.742066  ...   \n",
       "8163     0.912284    -0.141696      4.2339     -5.7269    1.638842  ...   \n",
       "8164     0.760463     0.104321      4.0206     -7.3882    2.183937  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "1915     0.148452    -9.392025     -9.3424     -9.4207    0.000242  ...   \n",
       "1916     0.368746    -9.398851     -9.3657     -9.4356    0.000156  ...   \n",
       "1917    -0.007991    -9.397350     -9.3628     -9.4313    0.000214  ...   \n",
       "1918    -0.114904    -9.397014     -9.3649     -9.4539    0.000257  ...   \n",
       "1919     0.608394    -9.398614     -9.3661     -9.4279    0.000167  ...   \n",
       "\n",
       "      LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  LL_zmag_var  \\\n",
       "8160      0.026911     -0.452746     -0.42401     -0.48635     0.000261   \n",
       "8161      0.587490     -0.433809     -0.40023     -0.46888     0.000238   \n",
       "8162      0.494886     -0.404305     -0.34281     -0.45115     0.000443   \n",
       "8163      0.353853     -0.369328     -0.33381     -0.41835     0.000354   \n",
       "8164      0.329407     -0.400433     -0.35154     -0.43797     0.000246   \n",
       "...            ...           ...          ...          ...          ...   \n",
       "1915      0.401254     -0.410987     -0.38221     -0.44605     0.000099   \n",
       "1916      0.147180     -0.411248     -0.36581     -0.43676     0.000087   \n",
       "1917      0.032341     -0.409787     -0.37926     -0.43431     0.000073   \n",
       "1918      0.409508     -0.409101     -0.36074     -0.44087     0.000113   \n",
       "1919      0.413339     -0.410440     -0.38588     -0.43841     0.000072   \n",
       "\n",
       "      LL_zmag_std  LL_zmag_skew   activity  people  Class  \n",
       "8160     0.016168      0.032586    jumping      p1    1.0  \n",
       "8161     0.015440      0.093940    jumping      p1    1.0  \n",
       "8162     0.021043      0.243550    jumping      p1    1.0  \n",
       "8163     0.018816     -0.312305    jumping      p1    1.0  \n",
       "8164     0.015679      0.549612    jumping      p1    1.0  \n",
       "...           ...           ...        ...     ...    ...  \n",
       "1915     0.009967     -0.597598  lyingRigh      p8    0.0  \n",
       "1916     0.009306      1.021454  lyingRigh      p8    0.0  \n",
       "1917     0.008520      0.431012  lyingRigh      p8    0.0  \n",
       "1918     0.010620      1.368666  lyingRigh      p8    0.0  \n",
       "1919     0.008495      0.054973  lyingRigh      p8    0.0  \n",
       "\n",
       "[1440 rows x 273 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5eea4295-d909-4405-aeea-634cf26c77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = X_test['Class']\n",
    "X_test = X_test.drop(['activity', 'people', 'Class'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1bd6dcdf-08c7-4344-a9cf-26b2cca81015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-10 10:03:25.666434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "136a587d-ff64-4bcf-aa86-59ef5bd94273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = np.mean(np.power(X_test - predictions, 2), axis=1)\n",
    "len(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "39c2fc8a-a0c6-4bf5-a227-dcc379104ce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1440.000000</td>\n",
       "      <td>1440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>175.463807</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.535286</td>\n",
       "      <td>0.471568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.498476</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.703991</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.033002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>145.512864</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.911926</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error   true_class\n",
       "count           1440.000000  1440.000000\n",
       "mean             175.463807     0.333333\n",
       "std              348.535286     0.471568\n",
       "min                4.498476     0.000000\n",
       "25%                4.703991     0.000000\n",
       "50%                5.033002     0.000000\n",
       "75%              145.512864     1.000000\n",
       "max             2930.911926     1.000000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': testdata})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4688b037-08d7-4354-b145-610d3c9c3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 값을 조정하여 최선의 정확도를 얻음, 그래프로를 보고 결정\n",
    "\n",
    "threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb0357dd-3e02-4130-be2f-4334fd453b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = error_df.groupby('true_class')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.reconstruction_error, marker='o', ms=3.5, linestyle='',\n",
    "            label= \"Abnormal\" if name == 1 else \"Normal\")\n",
    "ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"r\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for different classes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "577c3152-4de3-4e33-96da-59b00c4ad14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NaN 값이 있는 행을 제거\n",
    "error_df = error_df.dropna(subset=['true_class'])\n",
    "\n",
    "# 이후 confusion_matrix 계산\n",
    "y_pred = [1 if e > threshold else 0 for e in error_df['reconstruction_error'].values]\n",
    "conf_matrix = confusion_matrix(error_df['true_class'], y_pred)\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "10eab4fc-c825-4405-b082-366079f144bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       960\n",
      "         1.0       1.00      1.00      1.00       480\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(error_df.true_class, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180f400-3bf8-41ea-a94f-23003b956a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
